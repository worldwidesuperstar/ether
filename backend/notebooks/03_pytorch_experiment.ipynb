{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "bazt3cv8u9j",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data\n",
      "\n",
      "users: tensor([1, 2, 3, 1, 2])\n",
      "movies: tensor([1, 1, 2, 2, 3])\n",
      "ratings: tensor([5.0000, 4.0000, 3.0000, 4.5000, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "user_ids = torch.tensor([1, 2, 3, 1, 2])\n",
    "movie_ids = torch.tensor([1, 1, 2, 2, 3])\n",
    "ratings = torch.tensor([5.0, 4.0, 3.0, 4.5, 2.0])\n",
    "\n",
    "print(f\"sample data\\n\")\n",
    "print(f\"users: {user_ids}\")\n",
    "print(f\"movies: {movie_ids}\")\n",
    "print(f\"ratings: {ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "caba5560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 1's movies: tensor([1, 2])\n",
      "user 1's ratings: tensor([5.0000, 4.5000])\n"
     ]
    }
   ],
   "source": [
    "# filtering\n",
    "u1_mask = (user_ids == 1)\n",
    "print(f\"user 1's movies: {movie_ids[u1_mask]}\")\n",
    "print(f\"user 1's ratings: {ratings[u1_mask]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b16c8122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 0: [-0.369  0.64   1.357 -2.306  0.014]\n",
      "user 1: [ 0.819 -0.166 -0.02   0.334 -0.618]\n",
      "user 2: [-0.194  0.634  1.155  0.971 -0.898]\n",
      "user 3: [ 0.093  1.078 -0.156 -0.394  0.302]\n",
      "\n",
      "\n",
      "movie 0: [-1.103  1.071 -1.077  1.314  0.294]\n",
      "movie 1: [-0.685  0.576 -0.404 -0.814  0.785]\n",
      "movie 2: [-0.38   0.997  0.246 -1.995  0.48 ]\n"
     ]
    }
   ],
   "source": [
    "n_users = 4\n",
    "n_movies = 3\n",
    "dim = 5\n",
    "\n",
    "user_embedding = nn.Embedding(n_users, dim)\n",
    "movie_embedding = nn.Embedding(n_movies, dim)\n",
    "\n",
    "for i in range(n_users):\n",
    "    user_vec = user_embedding(torch.tensor(i))\n",
    "    print(f\"user {i}: {user_vec.detach().numpy().round(3)}\") \n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for i in range(n_movies):\n",
    "    movie_vec = movie_embedding(torch.tensor(i))\n",
    "    print(f\"movie {i}: {movie_vec.detach().numpy().round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i7ljjlqjh6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: torch.Size([3, 10])\n",
      "movie embedding shape: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "user_ids_indexed = user_ids - 1\n",
    "movie_ids_indexed = movie_ids - 1\n",
    "\n",
    "class BasicRecommender(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, dim):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, dim)\n",
    "        self.movie_embedding = nn.Embedding(n_movies, dim)\n",
    "    \n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        user_vecs = self.user_embedding(user_ids)\n",
    "        movie_vecs = self.movie_embedding(movie_ids)\n",
    "        predictions = torch.sigmoid((user_vecs * movie_vecs).sum(dim=1)) * 4.5 + 0.5\n",
    "        return predictions\n",
    "\n",
    "model = BasicRecommender(n_users=3, n_movies=3, dim=10)\n",
    "print(f\"user embedding shape: {model.user_embedding.weight.shape}\")\n",
    "print(f\"movie embedding shape: {model.movie_embedding.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c8d050b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [2.48 4.15 1.43 2.07 4.99]\n",
      "actual: [5.  4.  3.  4.5 2. ]\n",
      "initial loss: 4.7349\n",
      "\n",
      "training...\n",
      "epoch 0, Loss: 4.7349\n",
      "epoch 20, Loss: 1.9049\n",
      "epoch 40, Loss: 1.7949\n",
      "epoch 60, Loss: 0.9944\n",
      "epoch 80, Loss: 0.3125\n",
      "predictions: [4.99 3.97 3.01 4.99 2.42]\n",
      "actual: [5.  4.  3.  4.5 2. ]\n",
      "final loss: 0.0828\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(user_ids_indexed, movie_ids_indexed)\n",
    "    print(f\"predictions: {predictions.detach().numpy().round(2)}\")\n",
    "    print(f\"actual: {ratings.numpy()}\")\n",
    "    initial_loss = loss_fn(predictions, ratings)\n",
    "    print(f\"initial loss: {initial_loss:.4f}\")\n",
    "\n",
    "print(\"\\ntraining...\")\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(user_ids_indexed, movie_ids_indexed)\n",
    "    loss = loss_fn(predictions, ratings)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "             print(f\"epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(user_ids_indexed, movie_ids_indexed)\n",
    "    print(f\"predictions: {predictions.detach().numpy().round(2)}\")\n",
    "    print(f\"actual: {ratings.numpy()}\")\n",
    "    initial_loss = loss_fn(predictions, ratings)\n",
    "    print(f\"final loss: {initial_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576c9cab",
   "metadata": {},
   "source": [
    "## sample training with 10k ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "eeff2998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 10000 rows\n",
      "cols: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "users: 66\n",
      "movies: 3,965\n",
      "encoded - Users: 66, Movies: 3965\n",
      "user indices: 0 to 65\n",
      "movie indices: 0 to 3964\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ratings_df = pd.read_csv('../data/raw/ml-32m/ratings.csv', nrows=10000)\n",
    "print(f\"read {len(ratings_df)} rows\")\n",
    "print(f\"cols: {ratings_df.columns.tolist()}\")\n",
    "print(f\"users: {ratings_df['userId'].nunique():,}\")\n",
    "print(f\"movies: {ratings_df['movieId'].nunique():,}\")\n",
    "\n",
    "# encode users and movies to unique integers\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user_idx'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['movie_idx'] = movie_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "n_users = len(user_encoder.classes_)\n",
    "n_movies = len(movie_encoder.classes_)\n",
    "\n",
    "print(f\"encoded - Users: {n_users}, Movies: {n_movies}\")\n",
    "print(f\"user indices: 0 to {n_users-1}\")\n",
    "print(f\"movie indices: 0 to {n_movies-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "83fa2b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 8,000 train, 2,000 test\n",
      "train tensors: torch.Size([8000])\n",
      "test tensors: torch.Size([2000])\n",
      "rating range: 0.5 - 5.0\n"
     ]
    }
   ],
   "source": [
    "# 80/20 training split\n",
    "shuffled_data = ratings_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "split_idx = int(0.8 * len(shuffled_data))\n",
    "\n",
    "train_data = shuffled_data[:split_idx]\n",
    "test_data = shuffled_data[split_idx:]\n",
    "\n",
    "print(f\"split: {len(train_data):,} train, {len(test_data):,} test\")\n",
    "\n",
    "train_users = torch.tensor(train_data['user_idx'].values, dtype=torch.long)\n",
    "train_movies = torch.tensor(train_data['movie_idx'].values, dtype=torch.long)  \n",
    "train_ratings = torch.tensor(train_data['rating'].values, dtype=torch.float)\n",
    "\n",
    "test_users = torch.tensor(test_data['user_idx'].values, dtype=torch.long)\n",
    "test_movies = torch.tensor(test_data['movie_idx'].values, dtype=torch.long)\n",
    "test_ratings = torch.tensor(test_data['rating'].values, dtype=torch.float)\n",
    "\n",
    "print(f\"train tensors: {train_users.shape}\")\n",
    "print(f\"test tensors: {test_users.shape}\")\n",
    "print(f\"rating range: {train_ratings.min():.1f} - {train_ratings.max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "8deb768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 40,310\n",
      "initial train loss: 4.3708\n",
      "\n",
      "training...\n",
      "epoch 0, Loss: 4.3708\n",
      "epoch 20, Loss: 4.3333\n",
      "epoch 40, Loss: 4.2710\n",
      "epoch 60, Loss: 4.2005\n",
      "epoch 80, Loss: 4.1217\n",
      "\n",
      "evaluating...\n",
      "final train loss: 4.0315\n",
      "final test loss: 4.0412\n",
      "\n",
      "sample predictions vs actual:\n",
      "predicted: 1.71, actual: 3.00\n",
      "predicted: 4.71, actual: 3.00\n",
      "predicted: 4.60, actual: 4.50\n",
      "predicted: 5.00, actual: 2.50\n",
      "predicted: 1.94, actual: 4.00\n"
     ]
    }
   ],
   "source": [
    "model = BasicRecommender(n_users=66, n_movies=3965, dim=10)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_fn = nn.MSELoss()\n",
    "print(f\"total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(train_users, train_movies)\n",
    "    initial_loss = loss_fn(predictions, train_ratings)\n",
    "    print(f\"initial train loss: {initial_loss:.4f}\")\n",
    "\n",
    "print(\"\\ntraining...\")\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(train_users, train_movies)\n",
    "    loss = loss_fn(predictions, train_ratings)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"\\nevaluating...\")\n",
    "with torch.no_grad():\n",
    "    train_predictions = model(train_users, train_movies)\n",
    "    test_predictions = model(test_users, test_movies)\n",
    "    \n",
    "    train_loss = loss_fn(train_predictions, train_ratings)\n",
    "    test_loss = loss_fn(test_predictions, test_ratings)\n",
    "    \n",
    "    print(f\"final train loss: {train_loss:.4f}\")\n",
    "    print(f\"final test loss: {test_loss:.4f}\")\n",
    "    \n",
    "    print(f\"\\nsample predictions vs actual:\")\n",
    "    for i in range(5):\n",
    "        print(f\"predicted: {test_predictions[i]:.2f}, actual: {test_ratings[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g66e9t4x0kf",
   "metadata": {},
   "source": [
    "## training with 100k ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r1wwrstcucf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 100k ratings...\n",
      "loaded: 100,000 ratings\n",
      "users: 626\n",
      "movies: 10,225\n",
      "encoded - Users: 626, Movies: 10,225\n",
      "split: 80,000 train, 20,000 test\n"
     ]
    }
   ],
   "source": [
    "print(\"loading 100k ratings...\")\n",
    "ratings_100k = pd.read_csv('../data/raw/ml-32m/ratings.csv', nrows=100000)\n",
    "print(f\"loaded: {len(ratings_100k):,} ratings\")\n",
    "print(f\"users: {ratings_100k['userId'].nunique():,}\")\n",
    "print(f\"movies: {ratings_100k['movieId'].nunique():,}\")\n",
    "\n",
    "# encode users and movies\n",
    "user_encoder_100k = LabelEncoder()\n",
    "movie_encoder_100k = LabelEncoder()\n",
    "\n",
    "ratings_100k['user_idx'] = user_encoder_100k.fit_transform(ratings_100k['userId'])\n",
    "ratings_100k['movie_idx'] = movie_encoder_100k.fit_transform(ratings_100k['movieId'])\n",
    "\n",
    "n_users_100k = len(user_encoder_100k.classes_)\n",
    "n_movies_100k = len(movie_encoder_100k.classes_)\n",
    "\n",
    "print(f\"encoded - Users: {n_users_100k:,}, Movies: {n_movies_100k:,}\")\n",
    "\n",
    "# train/test split\n",
    "shuffled_100k = ratings_100k.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "split_idx_100k = int(0.8 * len(shuffled_100k))\n",
    "\n",
    "train_data_100k = shuffled_100k[:split_idx_100k]\n",
    "test_data_100k = shuffled_100k[split_idx_100k:]\n",
    "\n",
    "print(f\"split: {len(train_data_100k):,} train, {len(test_data_100k):,} test\")\n",
    "\n",
    "# convert to tensors\n",
    "train_users_100k = torch.tensor(train_data_100k['user_idx'].values, dtype=torch.long)\n",
    "train_movies_100k = torch.tensor(train_data_100k['movie_idx'].values, dtype=torch.long)  \n",
    "train_ratings_100k = torch.tensor(train_data_100k['rating'].values, dtype=torch.float)\n",
    "\n",
    "test_users_100k = torch.tensor(test_data_100k['user_idx'].values, dtype=torch.long)\n",
    "test_movies_100k = torch.tensor(test_data_100k['movie_idx'].values, dtype=torch.long)\n",
    "test_ratings_100k = torch.tensor(test_data_100k['rating'].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58kw0p3yhyg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 626 users, 10,225 movies, dim=20\n",
      "total parameters: 217,020\n",
      "initial train loss: 5.0899\n",
      "\n",
      "training 100k dataset...\n",
      "epoch 0, Loss: 5.0899\n",
      "epoch 20, Loss: 5.0870\n",
      "epoch 40, Loss: 5.0826\n",
      "epoch 60, Loss: 5.0780\n",
      "epoch 80, Loss: 5.0733\n",
      "\n",
      "evaluating 100k model...\n",
      "final train loss: 5.0686\n",
      "final test loss: 5.0885\n",
      "test RMSE: 2.2558\n",
      "\n",
      "sample predictions vs actual:\n",
      "predicted: 4.26, actual: 5.00\n",
      "predicted: 0.65, actual: 4.00\n",
      "predicted: 5.00, actual: 3.50\n",
      "predicted: 4.32, actual: 5.00\n",
      "predicted: 4.93, actual: 5.00\n",
      "predicted: 3.61, actual: 3.00\n",
      "predicted: 0.50, actual: 3.00\n",
      "predicted: 2.12, actual: 4.00\n",
      "predicted: 0.50, actual: 4.00\n",
      "predicted: 2.84, actual: 3.50\n"
     ]
    }
   ],
   "source": [
    "# make model for 100k dataset\n",
    "model_100k = BasicRecommender(n_users=n_users_100k, n_movies=n_movies_100k, dim=20)\n",
    "optimizer_100k = torch.optim.SGD(model_100k.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_fn_100k = nn.MSELoss()\n",
    "\n",
    "print(f\"model: {n_users_100k:,} users, {n_movies_100k:,} movies, dim=20\")\n",
    "print(f\"total parameters: {sum(p.numel() for p in model_100k.parameters()):,}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    initial_predictions = model_100k(train_users_100k, train_movies_100k)\n",
    "    initial_loss = loss_fn_100k(initial_predictions, train_ratings_100k)\n",
    "    print(f\"initial train loss: {initial_loss:.4f}\")\n",
    "\n",
    "print(\"\\ntraining 100k dataset...\")\n",
    "for epoch in range(100):\n",
    "    optimizer_100k.zero_grad()\n",
    "    predictions = model_100k(train_users_100k, train_movies_100k)\n",
    "    loss = loss_fn_100k(predictions, train_ratings_100k)\n",
    "    loss.backward()\n",
    "    optimizer_100k.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"\\nevaluating 100k model...\")\n",
    "with torch.no_grad():\n",
    "    final_train_pred = model_100k(train_users_100k, train_movies_100k)\n",
    "    final_test_pred = model_100k(test_users_100k, test_movies_100k)\n",
    "    \n",
    "    final_train_loss = loss_fn_100k(final_train_pred, train_ratings_100k)\n",
    "    final_test_loss = loss_fn_100k(final_test_pred, test_ratings_100k)\n",
    "    \n",
    "    print(f\"final train loss: {final_train_loss:.4f}\")\n",
    "    print(f\"final test loss: {final_test_loss:.4f}\")\n",
    "    print(f\"test RMSE: {torch.sqrt(final_test_loss):.4f}\")\n",
    "    \n",
    "    print(f\"\\nsample predictions vs actual:\")\n",
    "    for i in range(10):\n",
    "        print(f\"predicted: {final_test_pred[i]:.2f}, actual: {test_ratings_100k[i]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
