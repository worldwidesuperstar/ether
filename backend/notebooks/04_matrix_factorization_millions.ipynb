{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "j8oue55jrgo",
   "metadata": {},
   "source": [
    "# matrix factorization with millions of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eejxg7tpo8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 2 million ratings...\n",
      "loaded: 2,000,000 ratings\n",
      "users: 12,773\n",
      "movies: 36,603\n",
      "encoded - users: 12,773, movies: 36,603\n",
      "rating distribution:\n",
      "rating\n",
      "0.5     35379\n",
      "1.0     60992\n",
      "1.5     31635\n",
      "2.0    123674\n",
      "2.5    103883\n",
      "3.0    374510\n",
      "3.5    268803\n",
      "4.0    523517\n",
      "4.5    189480\n",
      "5.0    288127\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load 2 million ratings\n",
    "print(\"loading 2 million ratings...\")\n",
    "ratings_df = pd.read_csv('../data/raw/ml-32m/ratings.csv', nrows=2000000)\n",
    "print(f\"loaded: {len(ratings_df):,} ratings\")\n",
    "print(f\"users: {ratings_df['userId'].nunique():,}\")\n",
    "print(f\"movies: {ratings_df['movieId'].nunique():,}\")\n",
    "\n",
    "# one number per user/movie\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user_idx'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['movie_idx'] = movie_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "n_users = len(user_encoder.classes_)\n",
    "n_movies = len(movie_encoder.classes_)\n",
    "\n",
    "print(f\"encoded - users: {n_users:,}, movies: {n_movies:,}\")\n",
    "print(f\"rating distribution:\")\n",
    "print(ratings_df['rating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "q9xumoqpci",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp  user_idx  movie_idx\n",
      "0   11597      555     4.0   831728797     11596        544\n",
      "1    7794     1729     4.0  1115993740      7793       1625\n",
      "2    1271     1292     3.0  1035652014      1270       1225\n",
      "3   10410      266     4.0  1040314968     10409        261\n",
      "4    1239     3578     3.5  1225301411      1238       3401\n",
      "split: 1,600,000 train, 400,000 test\n",
      "train tensors: torch.Size([1600000])\n",
      "test tensors: torch.Size([400000])\n",
      "rating range: 0.5 - 5.0\n",
      "average rating: 3.54\n"
     ]
    }
   ],
   "source": [
    "shuffled = ratings_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(shuffled.head())\n",
    "split_idx = int(0.8 * len(shuffled))\n",
    "\n",
    "train_data = shuffled[:split_idx]\n",
    "test_data = shuffled[split_idx:]\n",
    "\n",
    "print(f\"split: {len(train_data):,} train, {len(test_data):,} test\")\n",
    "\n",
    "train_users = torch.tensor(train_data['user_idx'].values, dtype=torch.long)\n",
    "train_movies = torch.tensor(train_data['movie_idx'].values, dtype=torch.long)  \n",
    "train_ratings = torch.tensor(train_data['rating'].values, dtype=torch.float)\n",
    "\n",
    "test_users = torch.tensor(test_data['user_idx'].values, dtype=torch.long)\n",
    "test_movies = torch.tensor(test_data['movie_idx'].values, dtype=torch.long)\n",
    "test_ratings = torch.tensor(test_data['rating'].values, dtype=torch.float)\n",
    "\n",
    "print(f\"train tensors: {train_users.shape}\")\n",
    "print(f\"test tensors: {test_users.shape}\")\n",
    "print(f\"rating range: {train_ratings.min():.1f} - {train_ratings.max():.1f}\")\n",
    "print(f\"average rating: {train_ratings.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04d19bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_bias = train_ratings.mean()\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors=50, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.movie_factors = nn.Embedding(n_movies, n_factors)\n",
    "\n",
    "        # some users rate higher than others\n",
    "        self.user_biases = nn.Embedding(n_users, 1)\n",
    "\n",
    "        # some movies are rated higher than others\n",
    "        self.movie_biases = nn.Embedding(n_movies, 1)\n",
    "\n",
    "        # bias globally average rating\n",
    "        self.global_bias = nn.Parameter(torch.tensor(global_bias))\n",
    "\n",
    "        # less overfit\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.user_factors.weight.data.normal_(0, 0.1)\n",
    "        self.movie_factors.weight.data.normal_(0, 0.1)\n",
    "        self.user_biases.weight.data.normal_(0, 0.01)\n",
    "        self.movie_biases.weight.data.normal_(0, 0.01)\n",
    "        \n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        user_vec = self.user_factors(user_ids)\n",
    "        movie_vec = self.movie_factors(movie_ids)\n",
    "        user_bias = self.user_biases(user_ids).squeeze()\n",
    "        movie_bias = self.movie_biases(movie_ids).squeeze()\n",
    "        \n",
    "        # apply dropout\n",
    "        user_vec = self.dropout(user_vec)\n",
    "        movie_vec = self.dropout(movie_vec)\n",
    "        \n",
    "        # using dot product + bias\n",
    "        dot_product = (user_vec * movie_vec).sum(dim=1)\n",
    "        raw_prediction = (\n",
    "            self.global_bias + \n",
    "            user_bias + \n",
    "            movie_bias + \n",
    "            dot_product\n",
    "        )\n",
    "        \n",
    "        return raw_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35b195ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 12,773 users, 36,603 movies, embedding_dim=20\n",
      "total parameters: 1,036,897\n",
      "sample initial predictions: tensor([3.5777, 3.5022, 3.5398, 3.6582, 3.5514])\n",
      "sample actual ratings: tensor([4.0000, 4.0000, 3.0000, 4.0000, 3.5000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/x0hxzz0x5gd0mzmvr8l7q5_40000gp/T/ipykernel_23053/99656908.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.global_bias = nn.Parameter(torch.tensor(global_bias))\n"
     ]
    }
   ],
   "source": [
    "model = MatrixFactorization(n_users=n_users, n_movies=n_movies, n_factors=20)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "print(f\"model: {n_users:,} users, {n_movies:,} movies, embedding_dim=20\")\n",
    "print(f\"total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# initial predictions\n",
    "with torch.no_grad():\n",
    "    initial_pred = model(train_users[:100], train_movies[:100])\n",
    "    print(f\"sample initial predictions: {initial_pred[:5]}\")\n",
    "    print(f\"sample actual ratings: {train_ratings[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "esvabbrv4hn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n",
      "initial loss: 1.1356\n",
      "epoch 0, loss: 1.1357\n",
      "epoch 20, loss: 0.7546\n",
      "epoch 40, loss: 0.5649\n",
      "epoch 60, loss: 0.5013\n",
      "epoch 80, loss: 0.4704\n",
      "training done\n",
      "\n",
      "final results:\n",
      "train loss: 0.4052\n",
      "test loss: 0.7181\n",
      "test RMSE: 0.8474\n",
      "\n",
      "sample predictions vs actual (10 samples from testset):\n",
      "predicted: 2.88, actual: 2.00\n",
      "predicted: 3.70, actual: 4.00\n",
      "predicted: 3.07, actual: 4.00\n",
      "predicted: 3.61, actual: 3.00\n",
      "predicted: 3.15, actual: 3.50\n",
      "predicted: 4.72, actual: 5.00\n",
      "predicted: 4.02, actual: 5.00\n",
      "predicted: 3.69, actual: 4.00\n",
      "predicted: 1.63, actual: 1.00\n",
      "predicted: 3.63, actual: 3.00\n"
     ]
    }
   ],
   "source": [
    "print(\"starting training...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    initial_pred = model(train_users, train_movies)\n",
    "    initial_loss = loss_fn(initial_pred, train_ratings)\n",
    "    print(f\"initial loss: {initial_loss:.4f}\")\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(train_users, train_movies)\n",
    "    loss = loss_fn(predictions, train_ratings)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"epoch {epoch}, loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"training done\")\n",
    "\n",
    "# evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_pred = model(train_users, train_movies)\n",
    "    test_pred = model(test_users, test_movies)\n",
    "    \n",
    "    train_loss = loss_fn(train_pred, train_ratings)\n",
    "    test_loss = loss_fn(test_pred, test_ratings)\n",
    "    test_rmse = torch.sqrt(test_loss)\n",
    "    \n",
    "    print(f\"\\nfinal results:\")\n",
    "    print(f\"train loss: {train_loss:.4f}\")\n",
    "    print(f\"test loss: {test_loss:.4f}\")\n",
    "    print(f\"test RMSE: {test_rmse:.4f}\")\n",
    "    \n",
    "    print(f\"\\nsample predictions vs actual (10 samples from testset):\")\n",
    "    for i in range(10):\n",
    "        print(f\"predicted: {test_pred[i]:.2f}, actual: {test_ratings[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fi79iepq0y",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 87,585 movies\n",
      "\n",
      "sample predictions with movie titles:\n",
      "user 4287: 'Mr. & Mrs. Smith (2005)'\n",
      "  predicted: 2.88, actual: 2.00\n",
      "\n",
      "user 2364: '20,000 Leagues Under the Sea (1954)'\n",
      "  predicted: 3.70, actual: 4.00\n",
      "\n",
      "user 2863: 'American Pie (1999)'\n",
      "  predicted: 3.07, actual: 4.00\n",
      "\n",
      "user 2679: 'Batman (1989)'\n",
      "  predicted: 3.61, actual: 3.00\n",
      "\n",
      "user 10584: 'Aladdin (1992)'\n",
      "  predicted: 3.15, actual: 3.50\n",
      "\n",
      "user 10639: 'Nymphomaniac: Volume II (2013)'\n",
      "  predicted: 4.72, actual: 5.00\n",
      "\n",
      "user 4167: 'Her (2013)'\n",
      "  predicted: 4.02, actual: 5.00\n",
      "\n",
      "user 10584: 'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)'\n",
      "  predicted: 3.69, actual: 4.00\n",
      "\n",
      "user 6424: 'Scary Movie 4 (2006)'\n",
      "  predicted: 1.63, actual: 1.00\n",
      "\n",
      "user 8197: 'Kill Bill: Vol. 2 (2004)'\n",
      "  predicted: 3.63, actual: 3.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('../data/raw/ml-32m/movies.csv')\n",
    "print(f\"loaded {len(movies_df):,} movies\")\n",
    "\n",
    "def get_movie_titles(movie_indices, movie_encoder, movies_df):\n",
    "    original_movie_ids = movie_encoder.inverse_transform(movie_indices.numpy())\n",
    "    titles = []\n",
    "    for movie_id in original_movie_ids:\n",
    "        movie_row = movies_df[movies_df['movieId'] == movie_id]\n",
    "        if len(movie_row) > 0:\n",
    "            titles.append(movie_row['title'].iloc[0])\n",
    "        else:\n",
    "            titles.append(\"unknown movie\")\n",
    "    return titles\n",
    "\n",
    "print(f\"\\nsample predictions with movie titles:\")\n",
    "sample_indices = range(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_users_idx = test_users[sample_indices]\n",
    "    sample_movies_idx = test_movies[sample_indices]\n",
    "    sample_predictions = model(sample_users_idx, sample_movies_idx)\n",
    "    sample_actual = test_ratings[sample_indices]\n",
    "\n",
    "movie_titles = get_movie_titles(sample_movies_idx, movie_encoder, movies_df)\n",
    "original_user_ids = user_encoder.inverse_transform(sample_users_idx.numpy())\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"user {original_user_ids[i]}: '{movie_titles[i]}'\")\n",
    "    print(f\"  predicted: {sample_predictions[i]:.2f}, actual: {sample_actual[i]:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b9dfc9",
   "metadata": {},
   "source": [
    "for myself:\n",
    "\n",
    "i think i've gotten to a pretty good RMSE with just collaborative filtering, but i think i should start to factor in content a bit. might add in genre data for each movie and account for users' genre preferences. same with movie year, but might break it down into decades rather than continuous years"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
